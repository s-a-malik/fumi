{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = set()\n",
    "for i in range(1000):\n",
    "    x.add(i%10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = [1,2,3,4]\n",
    "for z in x[:-1]:\n",
    "    print(z)\n",
    "print(x[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class URLScraper():\n",
    "    \"\"\"\n",
    "        Given a base url, e.g. http://www.animalia.bio/social-animals, repeatedly click next page and store all the URLs observed along the way \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        \"\"\"\n",
    "            base_url -- where to start from, should take the form http://www.animalia.bio/X?page=1 e.g. http://www.animalia.bio/social-animals?page=1\n",
    "            file -- where to write the urls out to\n",
    "        \"\"\"\n",
    "        self.urls = set()\n",
    "        self.file = file\n",
    "        with open(file) as f:\n",
    "            for line in f.readlines():\n",
    "                self.urls.add(line.strip())\n",
    "                \n",
    "        self.MAX_DELAY = 10\n",
    "    \n",
    "    def write(self):\n",
    "        with open(self.file,'w') as f:\n",
    "            for u in self.urls:\n",
    "               f.write(u + \"\\n\")\n",
    "        \n",
    "    def traverse(self, base_url):\n",
    "        \"\"\"\n",
    "            Start at the first page and keep clicking to the next page until we run out of pages\n",
    "        \"\"\"\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('headless')\n",
    "        self.browser = webdriver.Chrome(options=options)\n",
    "        self.browser.get(base_url)\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            \n",
    "            # Load the page and wait for the Javascript to load until animals appear on the page\n",
    "            try:\n",
    "                _ = WebDriverWait(self.browser, self.MAX_DELAY).until(EC.presence_of_element_located((By.CLASS_NAME, 'item-animal')))\n",
    "                elements = self.browser.find_elements_by_class_name(\"item-animal\")\n",
    "                for e in elements:\n",
    "                    link = e.get_attribute(\"href\")\n",
    "                    self.urls.add(link.strip())\n",
    "                print(f\"Number of total species scraped: {len(self.urls)}\")\n",
    "            except TimeoutException:\n",
    "                pass\n",
    "        \n",
    "            # Attempt to click on the next page\n",
    "            try:\n",
    "                self.browser.find_element_by_link_text(str(page_number+1)).click()\n",
    "            except Exception:\n",
    "                self.write()\n",
    "                return\n",
    "            \n",
    "            # Wait for the new page to appear\n",
    "            try: \n",
    "                while not self.browser.find_element_by_link_text(str(page_number+1)).get_attribute(\"style\"):\n",
    "                    time.sleep(1)\n",
    "            except Exception:\n",
    "                time.sleep(10)\n",
    "            \n",
    "            page_number += 1\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_traverse = [\"http://animalia.bio/reptiles?page=1\", \"http://animalia.bio/mammals?page=1\", \"http://animalia.bio/social-animals?page=1\", \"http://animalia.bio/solitary-animals?page=1\",\n",
    "              \"http://animalia.bio/carnivore?page=1\", \"http://animalia.bio/cursorial?page=1\",\"http://animalia.bio/tropical-moist-forests?page=1\",\"http://animalia.bio/monogamy?page=1\",\n",
    "              \"http://animalia.bio/temperate-broadleaf-and-mixed-forest?page=1\",\"http://animalia.bio/birds?page=1\",\"http://animalia.bio/temperate?page=1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traversing: http://animalia.bio/reptiles?page=1\n",
      "Number of total species scraped: 42\n",
      "Number of total species scraped: 84\n",
      "Number of total species scraped: 126\n",
      "Number of total species scraped: 168\n",
      "Number of total species scraped: 210\n",
      "Number of total species scraped: 252\n",
      "Number of total species scraped: 259\n",
      "Traversing: http://animalia.bio/mammals?page=1\n",
      "Number of total species scraped: 301\n",
      "Number of total species scraped: 343\n",
      "Number of total species scraped: 385\n",
      "Number of total species scraped: 427\n",
      "Number of total species scraped: 469\n",
      "Number of total species scraped: 511\n",
      "Number of total species scraped: 553\n",
      "Number of total species scraped: 595\n",
      "Number of total species scraped: 637\n",
      "Traversing: http://animalia.bio/social-animals?page=1\n",
      "Number of total species scraped: 654\n",
      "Number of total species scraped: 671\n",
      "Number of total species scraped: 678\n",
      "Number of total species scraped: 678\n",
      "Number of total species scraped: 718\n",
      "Number of total species scraped: 740\n",
      "Number of total species scraped: 740\n",
      "Number of total species scraped: 745\n",
      "Number of total species scraped: 787\n",
      "Traversing: http://animalia.bio/solitary-animals?page=1\n",
      "Number of total species scraped: 787\n",
      "Number of total species scraped: 788\n",
      "Number of total species scraped: 802\n",
      "Number of total species scraped: 830\n",
      "Number of total species scraped: 866\n",
      "Number of total species scraped: 908\n",
      "Number of total species scraped: 918\n",
      "Number of total species scraped: 918\n",
      "Number of total species scraped: 939\n",
      "Number of total species scraped: 954\n",
      "Number of total species scraped: 964\n",
      "Traversing: http://animalia.bio/carnivore?page=1\n",
      "Number of total species scraped: 965\n",
      "Number of total species scraped: 967\n",
      "Number of total species scraped: 967\n",
      "Number of total species scraped: 974\n",
      "Number of total species scraped: 981\n",
      "Number of total species scraped: 1005\n",
      "Number of total species scraped: 1031\n",
      "Number of total species scraped: 1048\n",
      "Number of total species scraped: 1048\n",
      "Traversing: http://animalia.bio/cursorial?page=1\n",
      "Number of total species scraped: 1048\n",
      "Number of total species scraped: 1055\n",
      "Number of total species scraped: 1092\n",
      "Number of total species scraped: 1122\n",
      "Traversing: http://animalia.bio/tropical-moist-forests?page=1\n",
      "Number of total species scraped: 1122\n",
      "Number of total species scraped: 1122\n",
      "Number of total species scraped: 1122\n",
      "Number of total species scraped: 1122\n",
      "Number of total species scraped: 1122\n",
      "Number of total species scraped: 1126\n",
      "Number of total species scraped: 1141\n",
      "Number of total species scraped: 1160\n",
      "Number of total species scraped: 1202\n",
      "Traversing: http://animalia.bio/monogamy?page=1\n",
      "Number of total species scraped: 1203\n",
      "Number of total species scraped: 1203\n",
      "Number of total species scraped: 1203\n",
      "Number of total species scraped: 1203\n",
      "Number of total species scraped: 1209\n",
      "Number of total species scraped: 1226\n",
      "Number of total species scraped: 1241\n",
      "Number of total species scraped: 1283\n",
      "Number of total species scraped: 1324\n",
      "Number of total species scraped: 1366\n",
      "Number of total species scraped: 1408\n",
      "Number of total species scraped: 1441\n",
      "Number of total species scraped: 1443\n",
      "Traversing: http://animalia.bio/temperate-broadleaf-and-mixed-forest?page=1\n",
      "Number of total species scraped: 1443\n",
      "Number of total species scraped: 1443\n",
      "Number of total species scraped: 1445\n",
      "Number of total species scraped: 1451\n",
      "Number of total species scraped: 1462\n",
      "Number of total species scraped: 1468\n",
      "Number of total species scraped: 1468\n",
      "Number of total species scraped: 1477\n",
      "Number of total species scraped: 1484\n",
      "Number of total species scraped: 1495\n",
      "Number of total species scraped: 1506\n",
      "Traversing: http://animalia.bio/birds?page=1\n",
      "Number of total species scraped: 1506\n",
      "Number of total species scraped: 1507\n",
      "Number of total species scraped: 1507\n",
      "Number of total species scraped: 1509\n",
      "Number of total species scraped: 1513\n",
      "Number of total species scraped: 1523\n",
      "Number of total species scraped: 1529\n",
      "Number of total species scraped: 1535\n",
      "Number of total species scraped: 1541\n",
      "Number of total species scraped: 1551\n",
      "Number of total species scraped: 1562\n",
      "Number of total species scraped: 1568\n",
      "Traversing: http://animalia.bio/temperate?page=1\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1568\n",
      "Number of total species scraped: 1570\n"
     ]
    }
   ],
   "source": [
    "scraper = URLScraper(\"links.txt\")\n",
    "for t in to_traverse:\n",
    "    print(f\"Traversing: {t}\")\n",
    "    scraper.traverse(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animalia():\n",
    "    \n",
    "    def __init__(self, url):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://www.animalia.bio/\"\n",
    "test_species = [\"pine-siskin\",\"radiated-tortoise\",\"gharial\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Animalia', 'Chordata', 'Aves', 'Passeriformes', 'Fringillidae', 'Carduelinae', 'Spinus', 'Spinus pinus']\n",
      "8\n",
      "The pine siskin is brown on its upperparts and pale on its underparts, with heavy streaks over its body. Their tails are short and forked. Like most finches, their beaks are conical but are longer and more slender. Pine siskins have patches of yellow on their tails and wings, and sometimes white streaks on their wings as well. They are distinguished from other birds by their smaller size, the streaking marks and whitish or yellow patches on their wings, their notched tail and relatively slender bills.\n",
      "PINE SISKIN\n",
      "['Animalia', 'Chordata', 'Vertebrata', 'Reptilia', 'Testudines', 'Cryptodira', 'Testudinoidea', 'Testudinidae', 'Astrochelys', 'Astrochelys radiata']\n",
      "10\n",
      "The Radiated tortoise that lives in Madagascar is amongst the most attractive of tortoises. Its high-domed, dark carapace has brilliant yellow markings that radiate out from the center of all its plates to make this tortoise's distinctive pattern. The shell’s dark pigment fades as the individual grows older, producing a shell of a lighter color. Males have longer tails and their under shell or plastron has a notch below the tail. Hatchlings are black and off-white, but soon develop the striking adult coloration.\n",
      "RADIATED TORTOISE\n",
      "['Animalia', 'Chordata', 'Vertebrata', 'Reptilia', 'Crocodilia', 'Gavialidae', 'Gavialis', 'Gavialis gangeticus']\n",
      "8\n",
      "Gharials are one of the biggest crocodilians (a group that includes alligators, crocodiles and caimans) and has the narrowest snout of these different species. Its common name is due to the bulbous nasal snout of adult males, which looks like an Indian pot with the name 'ghara'. The different physical appearance of males and females is unique to gharials amongst the crocodilians and accentuated by the male’s larger size. Furthermore, unlike other crocodilians, gharials have relatively weak legs, and a fully grown adult cannot raise its body off the ground.\n",
      "GHARIAL\n"
     ]
    }
   ],
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('headless')\n",
    "browser = webdriver.Chrome(options=options)\n",
    "for url in [base_url + s for s in test_species]:\n",
    "#     page = requests.get(url)\n",
    "#     soup = BeautifulSoup(page.content, 'html.parser')\n",
    "#     print(soup.find(class_=\"s-char-text\").p)\n",
    "    browser.get(url)\n",
    "    els = browser.find_elements_by_class_name(\"s-char-kinds__name\")\n",
    "    els = [e.text for e in els]\n",
    "    print(els)\n",
    "    print(len(els))\n",
    "    print(browser.find_element_by_class_name(\"s-char-text\").text)\n",
    "    print(browser.find_element_by_class_name(\"a-h1\").text)\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
