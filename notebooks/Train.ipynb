{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/s-a-malik/multi-few/blob/publish/notebooks/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "TO CHANGE LINK TO COLAB\n",
    "\n",
    "\n",
    "# FuMI\n",
    "\n",
    "Test running scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './multi-few # TO CHANGE'\n",
      "/Users/shreshth/Library/CloudStorage/OneDrive-Nexus365/Projects/CDT Conference 2022/code/fumi/notebooks\n"
     ]
    }
   ],
   "source": [
    "# clone the repo and install the dependencies\n",
    "!git clone https://github.com/s-a-malik/multi-few.git   # TO CHANGE\n",
    "%cd ./multi-few # TO CHANGE\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shreshth/Library/CloudStorage/OneDrive-Nexus365/Projects/CDT Conference 2022/code/fumi\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data\n",
    "# TODO\n",
    "import os\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "# unzip\n",
    "!unzip \"./data/iNat-Anim.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/shreshth/.netrc\n"
     ]
    }
   ],
   "source": [
    "# sign into wandb\n",
    "!wandb login <API_KEY>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shreshth/anaconda3/envs/nlp-project/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "running on device cpu\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
      "Completed tokenisation\n",
      "Precomputing BERT embeddings\n",
      "Completed embedding computation\n",
      "Completed tokenisation\n",
      "Precomputing BERT embeddings\n",
      "Completed embedding computation\n",
      "Completed tokenisation\n",
      "Precomputing BERT embeddings\n",
      "Completed embedding computation\n",
      "FUMI(\n",
      "  (text_encoder): Identity()\n",
      "  (im_net): MetaSequential(\n",
      "    (linear0): MetaLinear(in_features=2048, out_features=256, bias=True)\n",
      "    (relu0): ReLU()\n",
      "    (dropout0): Dropout(p=0.25, inplace=False)\n",
      "    (linear1): MetaLinear(in_features=256, out_features=64, bias=True)\n",
      "    (relu1): ReLU()\n",
      "    (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (hyper_net): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=65, bias=True)\n",
      "  )\n",
      ")\n",
      "Test:   0%|                                             | 0/125 [00:00<?, ?it/s]/Users/shreshth/anaconda3/envs/nlp-project/lib/python3.8/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "Test: 100%|███████████████████████████████████| 125/125 [05:17<00:00,  2.54s/it]\n",
      "Train:   0%|                                           | 0/2500 [00:00<?, ?it/s]\n",
      "initial loss: 1.5084857751452734, acc: 0.5974801577745922\n",
      "Train:  49%|███████████████▊                | 1234/2500 [04:59<05:01,  4.20it/s]^C\n",
      "Traceback (most recent call last):\n",
      "  File \"fumi/main.py\", line 156, in <module>\n",
      "    main(args)\n",
      "  File \"fumi/main.py\", line 84, in main\n",
      "    model = fumi.training_run(args, model, optimizer, train_loader,\n",
      "  File \"/Users/shreshth/Library/CloudStorage/OneDrive-Nexus365/Projects/CDT Conference 2022/code/fumi/fumi/models/fumi.py\", line 297, in training_run\n",
      "    model, _ = utils.load_checkpoint(model, opt, args.device, best_file)\n",
      "  File \"/Users/shreshth/Library/CloudStorage/OneDrive-Nexus365/Projects/CDT Conference 2022/code/fumi/fumi/utils/utils.py\", line 434, in load_checkpoint\n",
      "    f\"trained to epoch {checkpoint['batch_idx']} with best loss (acc for CLIP) {checkpoint['best_loss']}\"\n",
      "  File \"/Users/shreshth/anaconda3/envs/nlp-project/lib/python3.8/site-packages/torch/serialization.py\", line 579, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/Users/shreshth/anaconda3/envs/nlp-project/lib/python3.8/site-packages/torch/serialization.py\", line 230, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/Users/shreshth/anaconda3/envs/nlp-project/lib/python3.8/site-packages/torch/serialization.py\", line 211, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/shreshth/Library/CloudStorage/OneDrive-Nexus365/Projects/CDT Conference 2022/code/fumi/wandb/offline-run-20220623_170937-2oeiobkn/files/best.pth.tar'\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "!python fumi/main.py --data_dir \"./data\" --wandb_entity \"multimodal-image-cls\" --wandb_project \"fumi\" --wandb_experiment fumi-5-shots \\\n",
    "   --model fumi --num_shots 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('nlp-project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3283e331221d3e092a4746895d21e49560347405c373e66aef669189d4d2967a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
